---
layout:     post
title:      Spark原理 | 内存管理
subtitle:   Spark原理之内存管理机制
date:       2021-10-18
author:     MichealHu
header-img: img/post-bg-swift.jpg
catalog: true
tags:
    - Spark

---

# Spark原理 | 内存管理

Spark作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。<br />在执行Spark的应用程序时，Spark集群会启动Driver和Executor两种JVM进程：

- Driver进程：为主控进程，负责创建Spark上下文对象，提交Spark作业(Job)，并将作业转化为计算任务(Task)，在各个Executor进程之间协调任务的调度。
- Executor进程：负责在工作节点上执行具体的计算任务，并将结果返回给Driver，同时为需要持久化的RDD提供存储功能。

# 一、Spark内存模型

## 1、Spark管理的内存

Spark管理的内存主要划分为4个区域：

1. 系统区：Spark运行自身的代码需要一定的内存空间。
1. 用户区：用户自己写的一些UDF之类的代码也需要一定的空间来运行。
1. 存储区：Spark的任务就是操作数据，Spark将数据尽可能的存储在内存，而这些数据也需要占用内存空间。
1. 执行区：Spark操作数据的单元是Partition，Spark在执行一些Shuffle、Join、Sort、Aggregation之类的操作，需要把Partition加载到内存进行运算，这也会运用到部分内存。
   <a name="lR2rK"></a>

## 2、Spark内存模型

![Spark内存模型.png](https://cdn.nlark.com/yuque/0/2021/png/1109132/1623770871473-f92bd610-25d5-41ba-b9fb-e7403aaebd01.png#height=545&id=aCDnc&margin=%5Bobject%20Object%5D&name=Spark%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png&originHeight=545&originWidth=928&originalType=binary&ratio=1&size=31745&status=done&style=none&width=928)

- 第一层：整个Executor所用到的内存；
- 第二层：分为JVM中的内存和JVM外的内存，这里的JVM内存在Yarn的时候就是指申请的Container的内存；
- 第三层：对于Spark来说内存分为三部分：堆内内存、Memory Overhead、堆外内存
  - On-heap：堆内内存。
  - Memory Overhead：对应的参数为：spark.yarn.executor.memoryOverhead。这块的内存主要用于虚拟机的开销，内部的字符串，还有一些本地开销（比如python需要用到的内存）等。其实就是额外的内存，spark并不会对这块内存进行管理。
  - Off-Heap：对应的参数为：spark.memory.offHeap.size。广义上是指所有的堆外内存，这部分内存的申请和释放是直接进行的，不通过JVM管控，所以没有GC，被Spark分为 Storage 和 Execution两部分，进行统一管理。
- 第四层：JVM堆内内存分为三个部分：
  - Reserved Memory：预留内存300M，用于保障Spark正常运行
  - Other Memory：用于Spark内部的一些元数据、用户的数据结构、防止出现对内存估计不足导致OOM时的内存缓存、占用空间比较大的记录做缓存
  - Memory Faction：spark主要控制的内存，由参数 spark.memory.faction 配置。
- 第五层：分为Storage 和 Execution。由参数 spark.memory.storageFraction配置它们两大小。
  - Execution：执行内存。用于Spark的计算，shuffle、sort、aggregation等计算时会用到的内存，如果计算时内存不足则会向Storage部分借用内存，如果还是不够就会spill到磁盘
  - Storage：主要用于RDD的缓存，如果Execution 来借内存，可能会牺牲自己丢弃缓存来借给Execution，Storage也可以向Execution借内存，但是Execution不会牺牲自己。
    <a name="S2iBb"></a>

# 二、堆内和堆外内存规划

Executor的堆内内存和对外内存如下图所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2021/png/1109132/1633222402959-93a65451-cf57-4f08-9e30-f1b9627fc5ef.png#clientId=u05239419-e532-4&from=paste&height=523&id=ufbc1b741&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1046&originWidth=1388&originalType=binary&ratio=1&size=656867&status=done&style=none&taskId=u73f19be6-eb55-46f1-af1f-c6037d90015&width=694)
<a name="JR0MI"></a>

## 1、堆内内存

堆内内存的大小，由 Spark 应用程序启动时的 executor-memory 或 spark.executor.memory 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同。<br />​

Spark 对堆内内存的管理是一种逻辑上的"规划式"的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：

- 申请内存：
  - Spark在代码中new一个实例对象；
  - JVM从堆内内存分配空间；
  - Spark 保存该对象的引用，记录该对象占用的内存。
- 释放内存
  - Spark记录该对象释放的内存，删除该对象的引用；
  - 等待JVM的垃圾回收机制释放该对象占用的堆内内存。
    <a name="aSp5y"></a>

## 2、堆外内存

为了进一步优化内存的使用以及<br />

<a name="j7C9o"></a>

# 三、内存管理模型

Spark 1.6 之后默认为统一管理（UnifiedMemoryManager）方式，1.6 之前采用的静态管理（StaticMemoryManager）方式仍被保留，可通过配置 spark.memory.useLegacyMode=true 参数启用静态内存管理方式。下面我们介绍下两种内存管理模型的进化。
<a name="dXpBC"></a>

## 1、静态内存管理


<a name="QYxMy"></a>

## 2、动态内存管理


<a name="eCYsd"></a>

# 参考资料

1. [从源码解读spark内存管理](https://zhuanlan.zhihu.com/p/63187650)
1. [Spark内存管理的基本原理](https://mp.weixin.qq.com/s?__biz=MzI4MzY5MDU5Mg==&mid=2247483849&idx=1&sn=3a53d18d44a0c272e570ddafe1cd904d&chksm=eb8792c6dcf01bd04110e20459718cac96295213802d0dda066c350c4486206865664978714b&scene=21#wechat_redirect)​